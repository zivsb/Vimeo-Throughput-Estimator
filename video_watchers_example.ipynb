{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa968f3f-fa5c-4a80-9619-3ddb5029a2f0",
   "metadata": {},
   "source": [
    "In this example we will do the interesting stuff - we will watch videos from different video platforms and capturing the corresponding traffic.\n",
    "\n",
    "Watching video is a pretty popular task, used for Quality of Experience research, Variable Bit Rate experiments, traffic-based video classification, etc. Let's collect a toy dataset using netunicorn platform for these tasks.\n",
    "\n",
    "As usual, we need to import all needed classes and tasks. This time we are again using our beautiful netunicorn-library and preimplemented tasks for watching YouTube, Vimeo, and Twitch videos. Please, visit the corresponding GitHub repository (https://github.com/netunicorn/netunicorn-library) if you're interested in tasks details or want to contribute your tasks and pipelines.\n",
    "\n",
    "_Important:_ for this example, we assume that you already explored the basic example and familiar with netunicorn principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bfb2e24-8b42-44c1-b07f-7ab7c9258208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from netunicorn.client.remote import RemoteClient, RemoteClientException\n",
    "from netunicorn.base import Experiment, ExperimentStatus, Pipeline\n",
    "\n",
    "# Tasks to start tcpdump and stop named tcpdump task\n",
    "from netunicorn.library.tasks.capture.tcpdump import StartCapture, StopNamedCapture\n",
    "\n",
    "# Upload to file.io - public anonymous temporary file storage\n",
    "from netunicorn.library.tasks.upload.fileio import UploadToFileIO\n",
    "\n",
    "# Tasks for watching the corresponding video platform\n",
    "from netunicorn.library.tasks.video_watchers.youtube_watcher import WatchYouTubeVideo\n",
    "from netunicorn.library.tasks.video_watchers.vimeo_watcher import WatchVimeoVideo\n",
    "from netunicorn.library.tasks.video_watchers.twitch_watcher import WatchTwitchStream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3064a16-6792-43c3-af6f-07d184c09dec",
   "metadata": {},
   "source": [
    "As the next step, let's assemble our pipeline. We should start the traffic capture, then watch three absolutely random videos (or streams) from YouTube, Vimeo, and Twitch correspondingly, and then again stop the data capture and upload the resulting PCAP file to some cloud. We again will use `file.io` for data upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee9838f-e8fc-49e7-b39c-33951bd9ce25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    Pipeline()\n",
    "    .then(StartCapture(filepath=\"/tmp/capture.pcap\", name=\"capture\"))\n",
    "    .then(WatchYouTubeVideo(\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\", 10))\n",
    "    .then(WatchVimeoVideo(\"https://vimeo.com/375468729\", 10))\n",
    "    .then(WatchTwitchStream(\"https://www.twitch.tv/shroud\", 10))\n",
    "    .then(StopNamedCapture(start_capture_task_name=\"capture\"))\n",
    "    .then(UploadToFileIO(filepath=\"/tmp/capture.pcap\", expires=\"1d\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b384a4-e914-43b5-af79-4304af49f1ab",
   "metadata": {},
   "source": [
    "Most of the other code is not different from any experiment definition. Let's use correct credentials for our infrastructure (in your case they could be different, if you don't have netunicorn instance in your organization - you can deploy your own locally for testing purposes, see https://netunicorn.cs.ucsb.edu/examples for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e6293c-4841-454a-9d9c-e7ad62ee847a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you have .env file locally for storing credentials, skip otherwise\n",
    "if '.env' in os.listdir():\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(\".env\")\n",
    "\n",
    "NETUNICORN_ENDPOINT = os.environ.get('NETUNICORN_ENDPOINT', 'https://pinot.cs.ucsb.edu/netunicorn')\n",
    "NETUNICORN_LOGIN = os.environ.get('NETUNICORN_LOGIN', 'team_tz')\n",
    "NETUNICORN_PASSWORD = os.environ.get('NETUNICORN_PASSWORD', 'throughput445')\n",
    "\n",
    "client = RemoteClient(endpoint=NETUNICORN_ENDPOINT, login=NETUNICORN_LOGIN, password=NETUNICORN_PASSWORD)\n",
    "client.healthcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dec4170-3bfb-4890-a0fb-62c8933d4706",
   "metadata": {},
   "source": [
    "Let's get some nodes for execution. As usual, for demonstration purposes of this notebook we will take our Raspberry Pi nodes, but if your infrastructure is different - feel free to modify the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6167c041-adbf-41cf-8db2-ca56595c5243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[raspi-e4:5f:01:9c:ca:3a, raspi-e4:5f:01:56:d9:a3, raspi-e4:5f:01:a7:b1:c1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = client.get_nodes()\n",
    "\n",
    "# switch for showing our infrastructure vs you doing it locally on other nodes\n",
    "if os.environ.get('NETUNICORN_ENDPOINT', 'https://pinot.cs.ucsb.edu/netunicorn') == 'https://pinot.cs.ucsb.edu/netunicorn':\n",
    "    working_nodes = nodes.filter(lambda node: node.name.startswith(\"raspi\")).take(3)\n",
    "else:\n",
    "    working_nodes = nodes.take(1)\n",
    "\n",
    "working_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da1465ef-fef6-4be9-9446-993acf524e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " - Deployment: Node=raspi-e4:5f:01:56:d9:a2, executor_id=, prepared=False, error=None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the experiment\n",
    "experiment = Experiment().map(pipeline, working_nodes)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef9add3-5847-43a6-9b2e-cf30853b9b65",
   "metadata": {},
   "source": [
    "When pipelines are assigned to nodes (and therefore, Deployments are created), each pipeline would have an \"environment_definition\" with a list of \"preparation\" commands to execute during Docker image compilation. We can explore these commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c6b8f6a-d8e4-4996-8f66-3c2df7cf02e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sudo apt-get update\n",
      "sudo apt-get install -y tcpdump\n",
      "apt install -y python3-pip wget xvfb procps chromium chromium-driver\n",
      "pip3 install selenium webdriver-manager\n",
      "apt install -y python3-pip wget xvfb procps chromium chromium-driver\n",
      "pip3 install selenium webdriver-manager\n",
      "apt install -y python3-pip wget xvfb procps chromium chromium-driver\n",
      "pip3 install selenium webdriver-manager\n",
      "sudo apt-get update\n",
      "sudo apt-get install -y tcpdump\n",
      "sudo apt-get install -y procps\n",
      "sudo apt-get install -y curl\n"
     ]
    }
   ],
   "source": [
    "for line in experiment[0].environment_definition.commands:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f044ca7-440a-43c8-86b7-92f2042daaef",
   "metadata": {},
   "source": [
    "Seems like we can optimize them a bit, as all watcher tasks use the same commands for configuration (at least, for now). Remember, that tasks do not know about each other in the pipeline, so they cannot resolve these duplications automatically.\n",
    "\n",
    "But, instead, let's ask experiment to use a predefined Docker image. This image was created by taking a base `python:3.10.9-slim` image and installing all the programs from the current environment. You can create and optimize your own image and use it on netunicorn platform as well, as soon as it's published on any public Docker repository (e.g., DockerHub).\n",
    "\n",
    "Please, note that any image used for the platform should have `netunicorn-executor` installed and `python3 -m netunicorn.executor` as the entrypoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e4d4678-4df9-4ea0-a65b-c31bb144b60c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from netunicorn.base import DockerImage\n",
    "for deployment in experiment:\n",
    "    # you can explore the image on the DockerHub\n",
    "    deployment.environment_definition = DockerImage(image='netunicorn/chromium:0.3.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42a1460-bd41-421f-8b1e-99c95162e93d",
   "metadata": {},
   "source": [
    "Ok, not let's define the experiment name and, as usual, prepare the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "564930b5-d394-4eff-ac3b-f9fcdb0f79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_label = \"video_watchers_example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dd12a3e-208b-49ae-bb2d-742815c48180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.READY\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client.delete_experiment(experiment_label)\n",
    "except RemoteClientException:\n",
    "    pass\n",
    "\n",
    "client.prepare_experiment(experiment, experiment_label)\n",
    "\n",
    "while True:\n",
    "    info = client.get_experiment_status(experiment_label)\n",
    "    print(info.status)\n",
    "    if info.status == ExperimentStatus.READY:\n",
    "        break\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d28b33-43dc-43c4-b134-44acaa010528",
   "metadata": {},
   "source": [
    "Verifying that everything is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceaa4766-7d3a-4b85-8872-d29cebfed0fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared: True, error: None\n"
     ]
    }
   ],
   "source": [
    "for deployment in client.get_experiment_status(experiment_label).experiment:\n",
    "    print(f\"Prepared: {deployment.prepared}, error: {deployment.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cdd81c-4041-4215-a315-1769f2711df3",
   "metadata": {},
   "source": [
    "And starting the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38418eee-2c51-410e-b01d-bfa069bea2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.FINISHED\n"
     ]
    }
   ],
   "source": [
    "client.start_execution(experiment_label)\n",
    "\n",
    "while True:\n",
    "    info = client.get_experiment_status(experiment_label)\n",
    "    print(info.status)\n",
    "    if info.status != ExperimentStatus.RUNNING:\n",
    "        break\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28849e1d-45f2-4e44-a76b-21aa863e554f",
   "metadata": {},
   "source": [
    "Moment of truth... /nervous drums sounds/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "274548bf-88f1-4e37-a6c8-e80699002891",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node name: raspi-e4:5f:01:56:d9:a2\n",
      "Error: None\n",
      "Result is: <class 'returns.result.Success'>\n",
      "container_value: defaultdict(<class 'list'>, {'capture': [<Success: {'container_value': 11}>], 'c8d042c1-6a44-4f77-9c38-63042fff08f4': [<Success: {'container_value': 'Video finished by timeout: 10 seconds'}>], '6ee855d6-d827-4e1b-8ed5-7e87b8d160ba': [<Success: {'container_value': 'Video finished by timeout: 10 seconds'}>], '8407e24a-b46d-4412-9cad-7d33a0bf50fa': [<Success: {'container_value': 'Video probably finished by timeout: 10 seconds'}>], '189f2c36-c00f-434a-8178-c67724a74b6b': [<Success: {'container_value': b''}>], '1aa5fbc8-9eb7-488a-97d2-edfe56018b90': [<Success: {'container_value': '{\"success\":true,\"status\":200,\"id\":\"e26eece0-7cfb-11ee-a149-2fef27717548\",\"key\":\"egG8jteY1PFl\",\"path\":\"/\",\"nodeType\":\"file\",\"name\":\"capture.pcap\",\"title\":null,\"description\":null,\"size\":44990882,\"link\":\"https://file.io/egG8jteY1PFl\",\"private\":false,\"expires\":\"2023-11-07T23:26:17.248Z\",\"downloads\":0,\"maxDownloads\":1,\"autoDelete\":true,\"planId\":0,\"screeningStatus\":\"pending\",\"mimeType\":\"application/octet-stream\",\"created\":\"2023-11-06T23:26:17.248Z\",\"modified\":\"2023-11-06T23:26:17.248Z\"}'}>]})\n",
      "Parsed configuration: Gateway located on https://pinot.cs.ucsb.edu/dev/netunicorn/gateway\n",
      "Current directory: /\n",
      "Successfully received pipeline.\n",
      "Pipeline finished, start reporting results.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from returns.pipeline import is_successful\n",
    "\n",
    "for report in info.execution_result:\n",
    "    print(f\"Node name: {report.node.name}\")\n",
    "    print(f\"Error: {report.error}\")\n",
    "\n",
    "    result, log = report.result  # report stores results of execution and corresponding log\n",
    "    \n",
    "    # result is a returns.result.Result object, could be Success of Failure\n",
    "    print(f\"Result is: {type(result)}\")\n",
    "    data = result.unwrap() if is_successful(result) else result.failure()\n",
    "    for key, value in data.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # we also can explore logs\n",
    "    for line in log:\n",
    "        print(line.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119fbe2-2cef-4bca-9016-0bccec55f855",
   "metadata": {},
   "source": [
    "Well, what could go wrong? :) ~(everything...)~  \n",
    "We successfully executed the experiment and watched 10 seconds of videos from YouTube, Vimeo, and Twitch, and recorded the network traffic for further analysis. Well, most likely it's the ad traffic from the corresponding platforms (as we intentionally did not used ad blockers in this example), but we did it anyway! :D  \n",
    "\n",
    "We encourage everyone to implement corresponding tasks or tasks modifications as you need and publish them to [netunicorn-library](https://github.com/netunicorn/netunicorn-library). As usual, our documenation and other examples are available on https://netunicorn.cs.ucsb.edu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
